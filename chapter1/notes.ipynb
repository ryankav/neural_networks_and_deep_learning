{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "\n",
    "A perceptron takes in multiple binary inputs $x_1, x_2, ..., x_n$ and returns a binary output.  \n",
    "  \n",
    "This means that a perceptron has is a map $f: \\mathbb{Z}^n_2 \\rightarrow \\mathbb{Z}_2$ . \n",
    "  \n",
    "In order to convert these binary inputs into a binary ouput we use weights. $w_1, w_2, ..., w_n$ where $w_j \\in \\mathbb{R}$. These weights are used to scale the inputs then summed to determine what the output should be based on if they are above or below a defined threshold.  \n",
    "  \n",
    "output = $\\begin{cases} \\text{0    if } \\sum_{j} w_j x_j \\leq \\text{threshold} \\\\ \\text{1    if } \\sum_{j} w_j x_j > \\text{threshold} \\end{cases}$ . \n",
    "  \n",
    "So the aim is to use the degrees of freedom given by the weights and the thresholds to come up with a model to make our decisions.  \n",
    "  \n",
    "### Network of perceptrons \n",
    "  \n",
    "To make the percepton model more plausible in it's decision making we mimic the approach that the brain uses. So we come up with layers of connected perceptons, which allows for ever more subtle and complex decisions to be made in later layers. When we consider the first layer all it can do is a dot product so can't model very complex deccisions. Yet by taking the output of this first layer and passing them into the input as a second layer allows the second layer to produce more complex decisions.  \n",
    "  \n",
    "### Mathmatical tidy up  \n",
    "  \n",
    "Previously spoke about the arbitary threshold, the more colloquial way to describe this is a bias where $b \\equiv -\\text{threshold}$ . \n",
    "  \n",
    "This means we can rewrite the previous equation as:  \n",
    "  \n",
    "output = $\\begin{cases} \\text{0    if } w \\cdot x + b \\leq 0\\\\ \\text{1    if } w \\cdot x + b > 0 \\end{cases}$ . \n",
    "  \n",
    "### As logical operators  \n",
    "  \n",
    "Whilst perceptrons can be used to weigh up evidence as described above, they can also be used to implement basic logical functions. Consider a single perceptron with two inputs where $w_0 = w_1 = -2$ and $b = 3$. In this instance if the input is $00, 10 \\text{ or } 01$ then the perceptron will output $1$ and if the input is $11$ the output is $0$. This means the above perceptron is a NAND gate. This is useful as the NAND gate is 'Functionally complete', means any truth table can be made out of combinations of NAND gates.  \n",
    "  \n",
    "This shows the benefit of the nework of perceptrons as at the simplest level we can build any logical circuit if needed. However, the benefit over logical operators comes from the ability to tune the weights and biases and therefore model even more complex decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid neurons  \n",
    "  \n",
    "To implement a learning algorithm we want is an algoritm that automatically adjusts the weights and biases of the network of neurons. \n",
    "Ideally what we desire, to implement this learning algorithm, is for a small change in the weights and biases to cause a corresponding small change in the networks output, to allow for gradual improvements.  \n",
    "\n",
    "If the network exhibits this property we could make these gradual improvements is by comparing the output we got to the desired output and then make a small change to the weights and biases to nudge it closer to the desired output.  \n",
    "\n",
    "Perceptron netowrks however do not exhibit this behaviour. A small change can cause a complete flip in the output of the perceptron. This makes the network hard to control - \"train\".  \n",
    "   \n",
    "The first change that we make to allow for a small change to cause a small change in the output is to change the *activation function* for the neuron. Now we define the neuron's activation function as a mapping:  \n",
    "  \n",
    "$f: [0,1]^n \\rightarrow [0,1]$  \n",
    "  \n",
    "For a sigmoid function the specific activation function is:  \n",
    "  \n",
    "$\\sigma(w \\cdot x + b)$  \n",
    "  \n",
    "where:  \n",
    "  \n",
    "$\\sigma(z) \\equiv \\frac{1}{1 + e^{-z}}$  \n",
    "  \n",
    "can see that in the limits when $z << 0$ we get $\\sigma(z) \\approx 0$ and when $z >>0$ we get $\\sigma(z) \\approx 1$. This show that in the extreme cases the sigmoid neuron behaves similar to the perceptron. However, between these limits we gain more control of the neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture  \n",
    "  \n",
    "*Terminology for neuron network, input layer and output layer are self explanatory and the hidden layers are every other layer.*  \n",
    "\n",
    "Often the design of the input layer is a given as it matches the space of the input data (likewise for the output), however there is some skill in designing the hidden layers. These are design heuristics that will be discussed later in the book.  \n",
    "  \n",
    "The type of networks we'll focus on our *feedforward* neural networks where there are no loops (no neurons output is used as an input to a prior layer). It is possible to designe *recurrent* neural networks where neurons fire for a limited time and then fire again later after it's previous output has stimulated neurons in proceeding layers. This is more akin to how the brain works but at the moment recurrent networks are less powerful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying handwritten digits\n",
    "  \n",
    "*two sub-problems to solve firstly correctly identifying an individual digit and then segmenting an image with multiple digits. The model discussed uses 784 ($28 \\times 28$ - one neuron for each pixel in image) input neurons, 15 neurons in the only hidden layer and 10 output neurons.*  \n",
    "\n",
    "The first question to ask is why use 10 outputs neurons rather than 4 (one output neuron for each bit required to encode 10 different digits)? The ultimate justification is empirical, however there is a good mental model for why it might be the case. When we consider what the network might do as it is plausible that a neuron in a hidden layer may focus on a certain region of the image - paying close attention with large weights and biases to that region of the input neurons - and fire based on their input. Then the output layer would piece together the results of the hidden layers to work out if it is a specific digit.  \n",
    "\n",
    "In contrast with the above approach if the output neuron was having to decide if a certain bit was set or not it isn't necessarily as clear how it could work with a hidden layer that had neurons focusing on specific regions. Whilst it might be possible for an algorithm to learn efficiently what bit is set it is less clear given the input data/evidence being used. There seems many more possible good ways to identify a digit from piecing together differnent shapes from regions of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "  \n",
    "In order to perform a learning algorithm we use training data where the input data is $x$ which has an expected output data, which for our identifying digit case is a 10 dimensional vector which if the desired output is 6 would be $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$.  \n",
    "  \n",
    "### Quantifying model output  \n",
    "  \n",
    "The aim of the modle is to approximate $y(x)$ as accuratley as possible for all the training set data. In or to quantify *\"as accurately as possible\"* so to do this we define a *cost function* - also known as a loss or objective function - which will be:  \n",
    "  \n",
    "$C(w,b) \\equiv \\frac{1}{2n} \\sum_{x} \\lVert y(x) - a(x,w,b) \\rVert^2$  \n",
    "  \n",
    "This form of $C$ is known as the *quadratic cost* function or the *mean squared error (MSE)*. Can see that $C(w,b) \\approx 0$ precisely when $w,b$ are set so that $y(x) \\approx a(x)\\vert_{w,b}$ for all elements $x$ of ther training data. So the aim of our learining algorithm is to minimise this cost function. The reason to do this rather than maximise correct clsifications is that minimising the cost gives us a way of incrementaly improving the weights and biases as the cost is a smooth function.  \n",
    "  \n",
    "The approach we'll take to solve this problem is gradient descent. For now rather than focus on the implementation details of the network focus on the minimisation problem of a multivariate function. In order to do this when the number of variables is very large can't solve analytically and computationally intensive to incluse second order partials, as $\\mathcal{O}(n^2)$ parital terms. So instead we can use the gradient operator to try and locally minimise our variables.  \n",
    "  \n",
    "As $\\Delta C \\approx \\nabla C \\cdot \\Delta v$ we can minimsie our function by chosing $\\Delta v = -\\eta \\nabla C$ then this will ensure that $\\Delta C$ is negative, as $\\Delta C \\approx - \\eta \\nabla C \\cdot \\nabla C = - \\eta \\lVert \\nabla C \\rVert ^2$. This definition is what causes the maximum decrease locally in our cost function. As such we define the size of our step to be small to ensure we are minimising our cost function.  \n",
    "  \n",
    "This strategy isn't full proof at finding the global maximum but in practice is a powerful way to minimise the cost function.\n",
    "\n",
    "### Mini-batch  \n",
    "  \n",
    "One of the issues with gradient descent is that the cost function, well at least for the function written above, is an average over each training example $x$. In practice to compute the gradients $\\nabla C$ we need to claculate $\\nabla C_x$ for each training input. As this can take a long time a practical approach is to implement *stochastic gradient descent*. As we can get a good estimate for $\\nabla C$ by sampling and averaging their gradients we can run more iterations of the algorithm and therefore 'learn' faster.  \n",
    "\n",
    "A *mini-batch* is a small number $m$ of randomly selected inputs. Where:\n",
    "\n",
    "$\\nabla C \\approx \\frac{1}{m} \\sum_{j=1}^{m} \\nabla C_{X_j}$  \n",
    "  \n",
    "Meaning we can estimate the overall gradient from these min batches. The aim is to train on this randomly selected mini-batch and then randomly select another mini-batch until we've exhausted the training inputs. At this point we say we've completed an *epoch* of training, after which we start another epoch."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
